{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7eRVlOdiwWW"
      },
      "source": [
        "# Importing data with `pandas`\n",
        "\n",
        "This notebook introduces basic techniques in using Python for data analysis - specifically how to use  `pandas` to get data into your notebook in order to analyse it.\n",
        "\n",
        "You can use different sections of the notebook to find code on the following, which you can then copy to your own notebook and adapt for the particular file/URL you are working with:\n",
        "\n",
        "* [Importing CSV files](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=1fexF0GrDePs)\n",
        "* [Importing Excel files](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=qrAreXx3yeSX)\n",
        "* [Importing JSON](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=jBrhMqJKDqg_)\n",
        "* [Importing from a URL](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=65rCbFiFXP2g)\n",
        "* [Importing an entire Excel file (not just one sheet)](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=qTe7ANH54Z6m)\n",
        "* [Importing from an ODS file](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=S5HWxqICxjHW)\n",
        "* [Exporting data](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=YqRunamXVMXt)\n",
        "* [Importing from GitHub](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=jsOTsPaqfJJd)\n",
        "* [Looping through Excel sheets to import them and combine](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=wFGQTT5efsYO)\n",
        "* [More functions for importing data](https://colab.research.google.com/drive/1TPKjZIcMSgDvadH5_slO8xiRnAODVV29#scrollTo=l5geK_86TzyL)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A note about Google Colab and Google Drive\n",
        "\n",
        "Before going any further it is important to understand the relationship between Google Colab notebooks and Google Drive.\n",
        "\n",
        "Google Drive runs on a **different computer** (or 'server') to Google Colab.\n",
        "\n",
        "This means that *Google Colab does not have access to data (or other files) in your Google Drive*.\n",
        "\n",
        "If you want to get data into a Colab notebook you will need to do one of the following:\n",
        "\n",
        "1. Upload the data file (CSV, XLSX etc) into the **Files** area on the left; or\n",
        "2. Import the data file from a URL. The URL *must* point to a CSV/XLSX/JSON/ODS file, not a webpage of data.\n",
        "3. Connect to your Google Drive and import from there. Instructions on how to do this are given below, but I would advise against this approach for reasons explained below.\n",
        "4. Create the data manually, by typing or pasting the data in lists, then combining those into a dataframe\n",
        "\n",
        "Another thing to remember is that each time you open a Colab notebook, it will connect to a **different computer**.\n",
        "\n",
        "The computer will be basically empty.Any files that were in your Colab notebook before will not be there now. For this reason, it is important to **always export any data that you need before closing your Colab notebook**."
      ],
      "metadata": {
        "id": "zyI1fBSZ1PQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the `pandas` library\n",
        "\n",
        "First, we need to import the `pandas` library. This is pre-installed in Colab notebooks, so doesn't need installing - it only needs bringing in with the `import` command.\n",
        "\n",
        "It's also quite common to rename the library when it's imported, as `pd`, like so:"
      ],
      "metadata": {
        "id": "6YLVpK2WwCNZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4zRPsakisxl"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5_5MQUojE4z"
      },
      "source": [
        "[The inverted pyramid of data journalism](https://onlinejournalismblog.com/2011/07/07/the-inverted-pyramid-of-data-journalism/) outlines 5 stages:\n",
        "\n",
        "1. Compile\n",
        "2. Clean\n",
        "3. Combine\n",
        "4. Context\n",
        "5. Clean\n",
        "\n",
        "And running throughout it: **question**.\n",
        "\n",
        "Let's start with compiling in `pandas`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fexF0GrDePs"
      },
      "source": [
        "## Compiling data: importing a CSV\n",
        "\n",
        "The easiest way to compile data in a Colab notebook is to upload the data to the Files area on the left hand side of Colab. Once in the Files view, it can be brought into the notebook with the `read_csv()` function.\n",
        "\n",
        "Colab already has a 'sample_data' folder in Files with 4 CSV files and a JSON file. We can import one of those to demonstrate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d1qecTSjYK8",
        "outputId": "3a2d37aa-9fe0-4a84-92fa-9b027287e071"
      },
      "source": [
        "#import the CSV from the Files in Colab\n",
        "caldata = pd.read_csv(\"sample_data/california_housing_test.csv\")\n",
        "#print the results\n",
        "print(caldata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0       -122.05     37.37                27.0       3885.0           661.0   \n",
            "1       -118.30     34.26                43.0       1510.0           310.0   \n",
            "2       -117.81     33.78                27.0       3589.0           507.0   \n",
            "3       -118.36     33.82                28.0         67.0            15.0   \n",
            "4       -119.67     36.33                19.0       1241.0           244.0   \n",
            "...         ...       ...                 ...          ...             ...   \n",
            "2995    -119.86     34.42                23.0       1450.0           642.0   \n",
            "2996    -118.14     34.06                27.0       5257.0          1082.0   \n",
            "2997    -119.70     36.30                10.0        956.0           201.0   \n",
            "2998    -117.12     34.10                40.0         96.0            14.0   \n",
            "2999    -119.63     34.42                42.0       1765.0           263.0   \n",
            "\n",
            "      population  households  median_income  median_house_value  \n",
            "0         1537.0       606.0         6.6085            344700.0  \n",
            "1          809.0       277.0         3.5990            176500.0  \n",
            "2         1484.0       495.0         5.7934            270500.0  \n",
            "3           49.0        11.0         6.1359            330000.0  \n",
            "4          850.0       237.0         2.9375             81700.0  \n",
            "...          ...         ...            ...                 ...  \n",
            "2995      1258.0       607.0         1.1790            225000.0  \n",
            "2996      3496.0      1036.0         3.3906            237200.0  \n",
            "2997       693.0       220.0         2.2895             62000.0  \n",
            "2998        46.0        14.0         3.2708            162500.0  \n",
            "2999       753.0       260.0         8.5608            500001.0  \n",
            "\n",
            "[3000 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrAreXx3yeSX"
      },
      "source": [
        "## Importing Excel files\n",
        "\n",
        "If your data is an Excel spreadsheet in .xlsx format you will need [pandas's `read_excel` function](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html).\n",
        "\n",
        "I've downloaded an Excel spreadsheet on [*Operation of police powers under the Terrorism Act 2000, financial year ending March 2021*](https://www.gov.uk/government/statistics/operation-of-police-powers-under-the-terrorism-act-2000-financial-year-ending-march-2021) and then uploaded it to the Files area in Colab.\n",
        "\n",
        "*Tip: once a file is in the Files area, you can click on the three dots next to the file and select **Copy path** to get the name of the file. It will begin with `/content/` because this is the complete path from the root of the computer, including any folders*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NekEGcNTzAvl",
        "outputId": "86a95570-1e3f-4679-d64f-13fe1a1c3a98"
      },
      "source": [
        "terrdata = pd.read_excel(\"operation-police-powers-terrorism-mar2021-annual-tables.xlsx\")\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 0                                         Unnamed: 1\n",
            "0          NaN                                                NaN\n",
            "1          NaN                                                NaN\n",
            "2          NaN                                                NaN\n",
            "3          NaN                                                NaN\n",
            "4          NaN                                                NaN\n",
            "5          NaN  Statistics on the operation of police powers u...\n",
            "6          NaN             Year to March 2021: Annual Data Tables\n",
            "7          NaN                                                NaN\n",
            "8          NaN                                                NaN\n",
            "9          NaN                                                NaN\n",
            "10         NaN                                                NaN\n",
            "11         NaN                                                NaN\n",
            "12         NaN              Responsible Statistician: Daniel Shaw\n",
            "13         NaN       Enquiries: CTAI_Statistics@homeoffice.gov.uk\n",
            "14         NaN                            Published: 10 June 2021\n",
            "15         NaN                             Crown copyright Â© 2021\n",
            "16         NaN                                                NaN\n",
            "17         NaN                                           Contents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBKGdfawzUnd"
      },
      "source": [
        "### Specifying which sheet you want\n",
        "\n",
        "Note that the spreadsheet has a bunch of `NaN` cells and unnamed columns. It's also imported the first sheet by default.\n",
        "\n",
        "You can control these by adding extra parameters to the `read_excel()` function like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3lUEoJc-ofw",
        "outputId": "e29bb08d-209d-4ff5-b841-6cef08a057e6"
      },
      "source": [
        "terrdata = pd.read_excel(\"operation-police-powers-terrorism-mar2021-annual-tables.xlsx\",\n",
        "                         sheet_name = 3,\n",
        "                         header=4)\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Unnamed: 0  ... Unnamed: 104\n",
            "0                                 Period of detention  ...        Total\n",
            "1                                                 NaN  ...          NaN\n",
            "2                                         Under 1 day  ...          757\n",
            "3                               1 to less than 2 days  ...          367\n",
            "4                               2 to less than 3 days  ...           57\n",
            "5                               3 to less than 4 days  ...          131\n",
            "6                               4 to less than 5 days  ...          115\n",
            "7                               5 to less than 6 days  ...          139\n",
            "8                               6 to less than 7 days  ...          260\n",
            "9                               7 to less than 8 days  ...           24\n",
            "10                              8 to less than 9 days  ...           24\n",
            "11                             9 to less than 10 days  ...           35\n",
            "12                            10 to less than 11 days  ...           21\n",
            "13                            11 to less than 12 days  ...           40\n",
            "14                            12 to less than 13 days  ...           34\n",
            "15                            13 to less than 14 days  ...           76\n",
            "16                            14 to less than 15 days  ...            1\n",
            "17                            15 to less than 16 days  ...            0\n",
            "18                            16 to less than 17 days  ...            0\n",
            "19                            17 to less than 18 days  ...            0\n",
            "20                            18 to less than 19 days  ...            1\n",
            "21                            19 to less than 20 days  ...            3\n",
            "22                            20 to less than 21 days  ...            0\n",
            "23                            21 to less than 22 days  ...            0\n",
            "24                            22 to less than 23 days  ...            0\n",
            "25                            23 to less than 24 days  ...            0\n",
            "26                            24 to less than 25 days  ...            0\n",
            "27                            25 to less than 26 days  ...            0\n",
            "28                            26 to less than 27 days  ...            0\n",
            "29                            27 to less than 28 days  ...            6\n",
            "30                                              Total  ...         2091\n",
            "31  Source: National Counter-Terrorism Police Oper...  ...          NaN\n",
            "32                                                NaN  ...          NaN\n",
            "33                                        ' - ' = Nil  ...          NaN\n",
            "34                             ' * ' = Not applicable  ...          NaN\n",
            "35  1.  Includes all detentions following an arres...  ...          NaN\n",
            "36  2.  The 'other' category includes cautions for...  ...          NaN\n",
            "37  3.  Data presented here are based on the lates...  ...          NaN\n",
            "38  4.  Totals since 11 September 2001 include tho...  ...          NaN\n",
            "39  5.  Figures for the year ending March 2002 inc...  ...          NaN\n",
            "\n",
            "[40 rows x 105 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdR1EHnE_Ney"
      },
      "source": [
        "### Other arguments/parameters\n",
        "\n",
        "Note that:\n",
        "\n",
        "* The first ingredient (argument) for `pd.read_excel(` is a string with the name of the spreadsheet, including .xlsx.\n",
        "* The second argument is `sheet_name =` which is set to `3` meaning the fourth sheet (counting begins at 0 in Python)\n",
        "* And the `skiprows =` argument is set to `5`, meaning that it will skip 5 rows and use row 6 for column headings.\n",
        "\n",
        "Other arguments are [listed in the documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html). Key ones to note are:\n",
        "\n",
        "* `header = ` - which row to use for column headings\n",
        "* `usecols = ` - which columns to keep. This can be column letter ranges as strings, e.g. `\"A:E\" or \"A,C,E:F\"`, or integers as a list, e.g. `[1:10]`\n",
        "* `nrows = ` - the number of rows to import. For example you might only want to import the first 100 rows to begin with in a large dataset, or all the rows before any footnotes\n",
        "* `skipfooter = ` is a similar argument which allows you to skip the last few rows by specifying how many rows at the end you want to leave out\n",
        "* `parse_dates = ` - specify which columns you want to import as dates, e.g. `[2,3]`. Check the documentation for more information on how to combine columns (e.g. day, month, year) as a date\n",
        "\n",
        "Here's an example of using more of those with our spreadsheet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggb_JEBZBomY",
        "outputId": "4240e7c6-8d2e-4f14-c292-b567e1c36c30"
      },
      "source": [
        "#store the url first so you can see all the arguments below\n",
        "theurlwewant = \"operation-police-powers-terrorism-mar2021-annual-tables.xlsx\"\n",
        "#read that url and specify a sheet name, header row and footers to skip\n",
        "terrdata = pd.read_excel(theurlwewant,\n",
        "                         sheet_name = 3,\n",
        "                         header = 5,\n",
        "                         skipfooter=10)\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Period of detention Charged Released  ... Released.20 Other.20  Total.20\n",
            "0                       NaN     NaN      NaN  ...         NaN      NaN       NaN\n",
            "1               Under 1 day       4       22  ...       556.0     63.0     757.0\n",
            "2     1 to less than 2 days       3       13  ...       257.0     26.0     367.0\n",
            "3     2 to less than 3 days       1        0  ...        30.0      1.0      57.0\n",
            "4     3 to less than 4 days       9        9  ...        56.0     16.0     131.0\n",
            "5     4 to less than 5 days       9        3  ...        55.0      9.0     115.0\n",
            "6     5 to less than 6 days       1        0  ...        52.0      6.0     139.0\n",
            "7     6 to less than 7 days       7        4  ...        78.0      8.0     260.0\n",
            "8     7 to less than 8 days       0        0  ...         8.0      5.0      24.0\n",
            "9     8 to less than 9 days       0        0  ...         7.0      1.0      24.0\n",
            "10   9 to less than 10 days       0        0  ...         9.0      2.0      35.0\n",
            "11  10 to less than 11 days       0        0  ...        11.0      0.0      21.0\n",
            "12  11 to less than 12 days       0        0  ...        12.0      0.0      40.0\n",
            "13  12 to less than 13 days       0        0  ...         8.0      3.0      34.0\n",
            "14  13 to less than 14 days       0        0  ...        14.0      7.0      76.0\n",
            "15  14 to less than 15 days       *        *  ...         0.0      0.0       1.0\n",
            "16  15 to less than 16 days       *        *  ...         0.0      0.0       0.0\n",
            "17  16 to less than 17 days       *        *  ...         0.0      0.0       0.0\n",
            "18  17 to less than 18 days       *        *  ...         0.0      0.0       0.0\n",
            "19  18 to less than 19 days       *        *  ...         0.0      0.0       1.0\n",
            "20  19 to less than 20 days       *        *  ...         0.0      0.0       3.0\n",
            "21  20 to less than 21 days       *        *  ...         0.0      0.0       0.0\n",
            "22  21 to less than 22 days       *        *  ...         0.0      0.0       0.0\n",
            "23  22 to less than 23 days       *        *  ...         0.0      0.0       0.0\n",
            "24  23 to less than 24 days       *        *  ...         0.0      0.0       0.0\n",
            "25  24 to less than 25 days       *        *  ...         0.0      0.0       0.0\n",
            "26  25 to less than 26 days       *        *  ...         0.0      0.0       0.0\n",
            "27  26 to less than 27 days       *        *  ...         0.0      0.0       0.0\n",
            "28  27 to less than 28 days       *        *  ...         3.0      0.0       6.0\n",
            "\n",
            "[29 rows x 105 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_WNvecqCJ8F",
        "outputId": "3a9e1e02-d084-4fce-b3a1-4c099a570b18"
      },
      "source": [
        "terrdata = pd.read_excel(\"operation-police-powers-terrorism-mar2021-annual-tables.xlsx\", sheet_name = 3, header = 5)\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  Period of detention Charged  ... Other.20 Total.20\n",
            "0                                                 NaN     NaN  ...      NaN      NaN\n",
            "1                                         Under 1 day       4  ...     63.0    757.0\n",
            "2                               1 to less than 2 days       3  ...     26.0    367.0\n",
            "3                               2 to less than 3 days       1  ...      1.0     57.0\n",
            "4                               3 to less than 4 days       9  ...     16.0    131.0\n",
            "5                               4 to less than 5 days       9  ...      9.0    115.0\n",
            "6                               5 to less than 6 days       1  ...      6.0    139.0\n",
            "7                               6 to less than 7 days       7  ...      8.0    260.0\n",
            "8                               7 to less than 8 days       0  ...      5.0     24.0\n",
            "9                               8 to less than 9 days       0  ...      1.0     24.0\n",
            "10                             9 to less than 10 days       0  ...      2.0     35.0\n",
            "11                            10 to less than 11 days       0  ...      0.0     21.0\n",
            "12                            11 to less than 12 days       0  ...      0.0     40.0\n",
            "13                            12 to less than 13 days       0  ...      3.0     34.0\n",
            "14                            13 to less than 14 days       0  ...      7.0     76.0\n",
            "15                            14 to less than 15 days       *  ...      0.0      1.0\n",
            "16                            15 to less than 16 days       *  ...      0.0      0.0\n",
            "17                            16 to less than 17 days       *  ...      0.0      0.0\n",
            "18                            17 to less than 18 days       *  ...      0.0      0.0\n",
            "19                            18 to less than 19 days       *  ...      0.0      1.0\n",
            "20                            19 to less than 20 days       *  ...      0.0      3.0\n",
            "21                            20 to less than 21 days       *  ...      0.0      0.0\n",
            "22                            21 to less than 22 days       *  ...      0.0      0.0\n",
            "23                            22 to less than 23 days       *  ...      0.0      0.0\n",
            "24                            23 to less than 24 days       *  ...      0.0      0.0\n",
            "25                            24 to less than 25 days       *  ...      0.0      0.0\n",
            "26                            25 to less than 26 days       *  ...      0.0      0.0\n",
            "27                            26 to less than 27 days       *  ...      0.0      0.0\n",
            "28                            27 to less than 28 days       *  ...      0.0      6.0\n",
            "29                                              Total      34  ...    147.0   2091.0\n",
            "30  Source: National Counter-Terrorism Police Oper...     NaN  ...      NaN      NaN\n",
            "31                                                NaN     NaN  ...      NaN      NaN\n",
            "32                                        ' - ' = Nil     NaN  ...      NaN      NaN\n",
            "33                             ' * ' = Not applicable     NaN  ...      NaN      NaN\n",
            "34  1.  Includes all detentions following an arres...     NaN  ...      NaN      NaN\n",
            "35  2.  The 'other' category includes cautions for...     NaN  ...      NaN      NaN\n",
            "36  3.  Data presented here are based on the lates...     NaN  ...      NaN      NaN\n",
            "37  4.  Totals since 11 September 2001 include tho...     NaN  ...      NaN      NaN\n",
            "38  5.  Figures for the year ending March 2002 inc...     NaN  ...      NaN      NaN\n",
            "\n",
            "[39 rows x 105 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBrhMqJKDqg_"
      },
      "source": [
        "## Importing JSON\n",
        "\n",
        "Data in the JSON format can be imported using `read_json`. Below we import another piece of data in Colab's 'sample_data' folder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02r-VRM-S-ZQ",
        "outputId": "298f8660-4a00-4471-f87f-a6bb9f3835cf"
      },
      "source": [
        "anscombe = pd.read_json(\"sample_data/anscombe.json\")\n",
        "print(anscombe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Series   X      Y\n",
            "0       I  10   8.04\n",
            "1       I   8   6.95\n",
            "2       I  13   7.58\n",
            "3       I   9   8.81\n",
            "4       I  11   8.33\n",
            "5       I  14   9.96\n",
            "6       I   6   7.24\n",
            "7       I   4   4.26\n",
            "8       I  12  10.84\n",
            "9       I   7   4.81\n",
            "10      I   5   5.68\n",
            "11     II  10   9.14\n",
            "12     II   8   8.14\n",
            "13     II  13   8.74\n",
            "14     II   9   8.77\n",
            "15     II  11   9.26\n",
            "16     II  14   8.10\n",
            "17     II   6   6.13\n",
            "18     II   4   3.10\n",
            "19     II  12   9.13\n",
            "20     II   7   7.26\n",
            "21     II   5   4.74\n",
            "22    III  10   7.46\n",
            "23    III   8   6.77\n",
            "24    III  13  12.74\n",
            "25    III   9   7.11\n",
            "26    III  11   7.81\n",
            "27    III  14   8.84\n",
            "28    III   6   6.08\n",
            "29    III   4   5.39\n",
            "30    III  12   8.15\n",
            "31    III   7   6.42\n",
            "32    III   5   5.73\n",
            "33     IV   8   6.58\n",
            "34     IV   8   5.76\n",
            "35     IV   8   7.71\n",
            "36     IV   8   8.84\n",
            "37     IV   8   8.47\n",
            "38     IV   8   7.04\n",
            "39     IV   8   5.25\n",
            "40     IV  19  12.50\n",
            "41     IV   8   5.56\n",
            "42     IV   8   7.91\n",
            "43     IV   8   6.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65rCbFiFXP2g"
      },
      "source": [
        "## Importing from a URL\n",
        "\n",
        "The same functions can also be used to import data an online source - you just need to use the URL of the file.\n",
        "\n",
        "Below we import CSV [from a GitHub repo](https://github.com/BBC-Data-Unit/stalking_protection_orders). GitHub displays CSVs nicely as tables - but note that in order to get the link to the actual CSV *data* you need to click on the CSV link in GitHub and *then* click on **Raw**. The URL should start `raw.githubusercontent.com`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pRrGZbrXIFS",
        "outputId": "7f5e18b9-0dac-4ea2-a6d3-451817fe39a9"
      },
      "source": [
        "stalkingdata = pd.read_csv(\"https://raw.githubusercontent.com/BBC-Data-Unit/stalking_protection_orders/main/forsharing_stalking_protection_orders%20-%20Main_dataset.csv\")\n",
        "print(stalkingdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Police force  ... charge_rate_apr20_dec20\n",
            "0      Avon and Somerset   ...                      4%\n",
            "1           Bedfordshire   ...                      4%\n",
            "2         Cambridgeshire   ...                      9%\n",
            "3               Cheshire   ...                      6%\n",
            "4              Cleveland   ...                      8%\n",
            "5                Cumbria   ...                      9%\n",
            "6             Derbyshire   ...                      6%\n",
            "7       Devon & Cornwall   ...                      8%\n",
            "8                 Dorset   ...                      7%\n",
            "9                 Durham   ...                      6%\n",
            "10            Dyfed Powys  ...                      7%\n",
            "11                 Essex   ...                      8%\n",
            "12       Gloucestershire   ...                     11%\n",
            "13    Greater Manchester   ...                 #DIV/0!\n",
            "14                  Gwent  ...                     11%\n",
            "15             Hampshire   ...                      6%\n",
            "16         Hertfordshire   ...                      8%\n",
            "17            Humberside   ...                      7%\n",
            "18                  Kent   ...                      2%\n",
            "19            Lancashire   ...                      5%\n",
            "20        Leicestershire   ...                      3%\n",
            "21          Lincolnshire   ...                      5%\n",
            "22            Merseyside   ...                     17%\n",
            "23  Metropolitan  Service  ...                      2%\n",
            "24               Norfolk   ...                      6%\n",
            "25            North Wales  ...                      5%\n",
            "26       North Yorkshire   ...                   #REF!\n",
            "27      Northamptonshire   ...                      5%\n",
            "28           Northumbria   ...                      6%\n",
            "29       Nottinghamshire   ...                     37%\n",
            "30            South Wales  ...                      3%\n",
            "31       South Yorkshire   ...                      3%\n",
            "32         Staffordshire   ...                      3%\n",
            "33               Suffolk   ...                     18%\n",
            "34                Surrey   ...                     23%\n",
            "35                Sussex   ...                      4%\n",
            "36         Thames Valley   ...                      7%\n",
            "37          Warwickshire   ...                     16%\n",
            "38           West Mercia   ...                      7%\n",
            "39         West Midlands   ...                      1%\n",
            "40        West Yorkshire   ...                      0%\n",
            "41             Wiltshire   ...                      0%\n",
            "\n",
            "[42 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWoDp2dbXtO6"
      },
      "source": [
        "The same process can be used to import Excel spreadsheets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdGd_nw0Xlfg",
        "outputId": "e49a96ee-99c0-4ee6-b07c-b29845ce611b"
      },
      "source": [
        "xlslink = \"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/991988/operation-police-powers-terrorism-mar2021-annual-tables.xlsx\"\n",
        "terrdata = pd.read_excel(xlslink, sheet_name=3, header=5)\n",
        "\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  Period of detention Charged  ... Other.20 Total.20\n",
            "0                                                 NaN     NaN  ...      NaN      NaN\n",
            "1                                         Under 1 day       4  ...     63.0    757.0\n",
            "2                               1 to less than 2 days       3  ...     26.0    367.0\n",
            "3                               2 to less than 3 days       1  ...      1.0     57.0\n",
            "4                               3 to less than 4 days       9  ...     16.0    131.0\n",
            "5                               4 to less than 5 days       9  ...      9.0    115.0\n",
            "6                               5 to less than 6 days       1  ...      6.0    139.0\n",
            "7                               6 to less than 7 days       7  ...      8.0    260.0\n",
            "8                               7 to less than 8 days       0  ...      5.0     24.0\n",
            "9                               8 to less than 9 days       0  ...      1.0     24.0\n",
            "10                             9 to less than 10 days       0  ...      2.0     35.0\n",
            "11                            10 to less than 11 days       0  ...      0.0     21.0\n",
            "12                            11 to less than 12 days       0  ...      0.0     40.0\n",
            "13                            12 to less than 13 days       0  ...      3.0     34.0\n",
            "14                            13 to less than 14 days       0  ...      7.0     76.0\n",
            "15                            14 to less than 15 days       *  ...      0.0      1.0\n",
            "16                            15 to less than 16 days       *  ...      0.0      0.0\n",
            "17                            16 to less than 17 days       *  ...      0.0      0.0\n",
            "18                            17 to less than 18 days       *  ...      0.0      0.0\n",
            "19                            18 to less than 19 days       *  ...      0.0      1.0\n",
            "20                            19 to less than 20 days       *  ...      0.0      3.0\n",
            "21                            20 to less than 21 days       *  ...      0.0      0.0\n",
            "22                            21 to less than 22 days       *  ...      0.0      0.0\n",
            "23                            22 to less than 23 days       *  ...      0.0      0.0\n",
            "24                            23 to less than 24 days       *  ...      0.0      0.0\n",
            "25                            24 to less than 25 days       *  ...      0.0      0.0\n",
            "26                            25 to less than 26 days       *  ...      0.0      0.0\n",
            "27                            26 to less than 27 days       *  ...      0.0      0.0\n",
            "28                            27 to less than 28 days       *  ...      0.0      6.0\n",
            "29                                              Total      34  ...    147.0   2091.0\n",
            "30  Source: National Counter-Terrorism Police Oper...     NaN  ...      NaN      NaN\n",
            "31                                                NaN     NaN  ...      NaN      NaN\n",
            "32                                        ' - ' = Nil     NaN  ...      NaN      NaN\n",
            "33                             ' * ' = Not applicable     NaN  ...      NaN      NaN\n",
            "34  1.  Includes all detentions following an arres...     NaN  ...      NaN      NaN\n",
            "35  2.  The 'other' category includes cautions for...     NaN  ...      NaN      NaN\n",
            "36  3.  Data presented here are based on the lates...     NaN  ...      NaN      NaN\n",
            "37  4.  Totals since 11 September 2001 include tho...     NaN  ...      NaN      NaN\n",
            "38  5.  Figures for the year ending March 2002 inc...     NaN  ...      NaN      NaN\n",
            "\n",
            "[39 rows x 105 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTe7ANH54Z6m"
      },
      "source": [
        "## Importing an entire Excel file (not just one sheet)\n",
        "\n",
        "You can also read an entire Excel file first in order to see what sheets it contains and select more than one sheet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pk-UBLyxuE8",
        "outputId": "bd8f2c8b-7423-4f22-89f5-6f41272b56ca"
      },
      "source": [
        "importme = \"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/991988/operation-police-powers-terrorism-mar2021-annual-tables.xlsx\"\n",
        "xlfile = pd.ExcelFile(importme)\n",
        "xlfile.sheet_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Front Page',\n",
              " 'A - Index',\n",
              " 'A - A.01',\n",
              " 'A - A.02',\n",
              " 'A - A.03',\n",
              " 'A - A.04',\n",
              " 'A - A.05a',\n",
              " 'A - A.05b',\n",
              " 'A - A.05c',\n",
              " 'A - A.06a',\n",
              " 'A - A.06b',\n",
              " 'A - A.06c',\n",
              " 'A - A.07',\n",
              " 'A - A.08a',\n",
              " 'A - A.08b',\n",
              " 'A - A.08c',\n",
              " 'A - A.09',\n",
              " 'A - A.10',\n",
              " 'A - A.11',\n",
              " 'A - A.12a',\n",
              " 'A - A.12b',\n",
              " 'A - A.12c',\n",
              " 'A C.01',\n",
              " 'A C.02',\n",
              " 'A C.03',\n",
              " 'A C.04',\n",
              " 'A C.05',\n",
              " 'A P.01',\n",
              " 'A P.02',\n",
              " 'A P.03',\n",
              " 'A P.04',\n",
              " 'A P.05',\n",
              " 'A P.06',\n",
              " 'A S.01',\n",
              " 'A S.02',\n",
              " 'A S.03',\n",
              " 'A S.04']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGqegahR4rY2",
        "outputId": "577a7f7f-9603-4d4d-cf61-32e87bf382f9"
      },
      "source": [
        "#read in an Excel file\n",
        "xlfile = pd.ExcelFile(\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/991988/operation-police-powers-terrorism-mar2021-annual-tables.xlsx\")\n",
        "#what are the sheet names?\n",
        "print(xlfile.sheet_names)\n",
        "#how many sheets\n",
        "print(len(xlfile.sheet_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Front Page', 'A - Index', 'A - A.01', 'A - A.02', 'A - A.03', 'A - A.04', 'A - A.05a', 'A - A.05b', 'A - A.05c', 'A - A.06a', 'A - A.06b', 'A - A.06c', 'A - A.07', 'A - A.08a', 'A - A.08b', 'A - A.08c', 'A - A.09', 'A - A.10', 'A - A.11', 'A - A.12a', 'A - A.12b', 'A - A.12c', 'A C.01', 'A C.02', 'A C.03', 'A C.04', 'A C.05', 'A P.01', 'A P.02', 'A P.03', 'A P.04', 'A P.05', 'A P.06', 'A S.01', 'A S.02', 'A S.03', 'A S.04']\n",
            "37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8rAQNIc6Fbm"
      },
      "source": [
        "If sheets contain the same data (e.g. a different sheet for each region, but the same columns) then this approach can be used to merge them, by looping through each sheet name you want to use."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing from an ODS file\n",
        "\n",
        "Public data is often published in the .ods format - this is an OpenDocument Spreadsheet. It's used because it's not 'proprietary' (i.e. owned by a company, like Microsoft)\n",
        "\n",
        "However, there is no `read_ods` function or equivalent. Instead, we need to use `read_excel` and install something extra to make it work with this format.\n",
        "\n",
        "Before we do that, here's what happens when we try to import from an .ods file using the 'normal' `read_excel()`:\n"
      ],
      "metadata": {
        "id": "S5HWxqICxjHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#try to import the ods file using read_excel\n",
        "foidata = pd.read_excel(\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1017270/foi-statistics-q2-2021-statistical-tables.ods\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "T7Oyw5jyxozf",
        "outputId": "9ed77c59-3393-4239-8c80-b8db4098a10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b1bb2839e250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoidata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1017270/foi-statistics-q2-2021-statistical-tables.ods\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_odfreader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFilePathOrBuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"odf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'odfpy'.  Use pip or conda to install odfpy.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing `odfpy`\n",
        "\n",
        "The error is a big clue to what you need to do to fix this.\n",
        "\n",
        "It says `ImportError: Missing optional dependency 'odfpy'.  Use pip or conda to install odfpy.`\n",
        "\n",
        "A 'dependency' is something else that a function *depends* on to be able to do something. In this case, the `read_excel()` function depends on another library being installed: [`odfpy`](https://pypi.org/project/odfpy/).\n",
        "\n",
        "Here is the code to do just that:"
      ],
      "metadata": {
        "id": "p8lxpqwHx1cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install the library we need\n",
        "!pip install odfpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUW7hGbCx4br",
        "outputId": "e552d601-ab47-4026-c1e3-c473790684eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting odfpy\n",
            "  Downloading odfpy-1.4.1.tar.gz (717 kB)\n",
            "\u001b[?25l\r\u001b[K     |â                               | 10 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |â                               | 20 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |ââ                              | 30 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |ââ                              | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |âââ                             | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |âââ                             | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |ââââ                            | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |ââââ                            | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |âââââ                           | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |âââââ                           | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââ                           | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââ                          | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââ                          | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââ                         | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââ                         | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââ                        | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââ                        | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââ                       | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââ                       | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââ                      | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââ                      | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââ                      | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââ                     | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââ                     | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââ                    | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââ                    | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââ                   | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââ                   | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââ                  | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââ                  | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââ                 | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââ                 | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââ                 | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââ                | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââ                | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââ               | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââ               | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââ              | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââ              | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââ             | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââ             | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââ            | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââ            | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââ            | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââ           | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââ           | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââ          | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââ          | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââ         | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââ         | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââ        | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââ        | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââ       | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââ       | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââ      | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââ      | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââ      | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââ     | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââ     | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââ    | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââ    | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââ   | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââ   | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââ  | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââ  | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââââ | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââââ | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââââ | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââââ| 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââââ| 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââââ| 717 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from odfpy) (0.7.1)\n",
            "Building wheels for collected packages: odfpy\n",
            "  Building wheel for odfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for odfpy: filename=odfpy-1.4.1-py2.py3-none-any.whl size=160692 sha256=d2773608ca8ad7f8807dce92fe98da48b831a460b830543b1671d4e6d8f8c48e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/f4/5d/a68c656235d33455a1d0f78e877acddfa006907a6d52d7e6ee\n",
            "Successfully built odfpy\n",
            "Installing collected packages: odfpy\n",
            "Successfully installed odfpy-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to try the code again to see if the error recurs."
      ],
      "metadata": {
        "id": "fo6i2DQMyB5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#try to import again with the new library installed\n",
        "foidata = pd.read_excel(\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1017270/foi-statistics-q2-2021-statistical-tables.ods\")"
      ],
      "metadata": {
        "id": "CpIurhZax8wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the code no longer generates an error, and works fine. So let's check the first few rows of the data."
      ],
      "metadata": {
        "id": "kp21Bb2ayFQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#show the first few rows\n",
        "foidata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "9DBHxhEWx_Nv",
        "outputId": "5a590a0a-7e47-41ed-9226-856f2971ba8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-185e27e8-3537-49e7-b1b9-698d4d491d73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Freedom of Information Statistics in Central Government Q2 2021 tables</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Worksheet 1</td>\n",
              "      <td>Number of non-routine information requests rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Worksheet 2</td>\n",
              "      <td>Number of non-routine information requests rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Worksheet 3</td>\n",
              "      <td>Timeliness of response to non-routine informat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Worksheet 4</td>\n",
              "      <td>Percentage of non-routine information requests...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-185e27e8-3537-49e7-b1b9-698d4d491d73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-185e27e8-3537-49e7-b1b9-698d4d491d73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-185e27e8-3537-49e7-b1b9-698d4d491d73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Freedom of Information Statistics in Central Government Q2 2021 tables                                         Unnamed: 1\n",
              "0                                                NaN                                                                    NaN\n",
              "1                                        Worksheet 1                      Number of non-routine information requests rec...\n",
              "2                                        Worksheet 2                      Number of non-routine information requests rec...\n",
              "3                                        Worksheet 3                      Timeliness of response to non-routine informat...\n",
              "4                                        Worksheet 4                      Percentage of non-routine information requests..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unless we specify otherwise, `read_excel()` reads the first sheet in an Excel workbook.\n",
        "\n",
        "We can now start to adapt our import code to grab the sheet we want, and skip and header rows etc."
      ],
      "metadata": {
        "id": "RtjNtBRlyIpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import again - this time sheet 2\n",
        "foidata = pd.read_excel(\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1017270/foi-statistics-q2-2021-statistical-tables.ods\",\n",
        "                        sheet_name = 2)\n",
        "#show the first few rows\n",
        "foidata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "GBEFtYiRyNv0",
        "outputId": "9d43a2fe-9eec-465f-d9cf-67308f895086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d7900bb0-1094-4f93-887e-2c80f22c2673\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Worksheet 1: Number of non-routine information requests received from 1 April to 30 June 2021, and their status at time of monitoring [note 1]</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This worksheet contains three tables presented...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Table 1a: Total figures</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Government body</td>\n",
              "      <td>Total requests received</td>\n",
              "      <td>Total requests processed</td>\n",
              "      <td>Total requests \"On hold\" or lapsed [note 2]</td>\n",
              "      <td>Total requests still being processed</td>\n",
              "      <td>Total requests handled under EIRs [note 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>All monitored bodies</td>\n",
              "      <td>12983</td>\n",
              "      <td>11918</td>\n",
              "      <td>5</td>\n",
              "      <td>1060</td>\n",
              "      <td>557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Departments of State</td>\n",
              "      <td>8938</td>\n",
              "      <td>8240</td>\n",
              "      <td>0</td>\n",
              "      <td>698</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7900bb0-1094-4f93-887e-2c80f22c2673')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7900bb0-1094-4f93-887e-2c80f22c2673 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7900bb0-1094-4f93-887e-2c80f22c2673');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Worksheet 1: Number of non-routine information requests received from 1 April to 30 June 2021, and their status at time of monitoring [note 1]  ...                                  Unnamed: 5\n",
              "0  This worksheet contains three tables presented...                                                                                              ...                                         NaN\n",
              "1                            Table 1a: Total figures                                                                                              ...                                         NaN\n",
              "2                                    Government body                                                                                              ...  Total requests handled under EIRs [note 3]\n",
              "3                               All monitored bodies                                                                                              ...                                         557\n",
              "4                               Departments of State                                                                                              ...                                         299\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqRunamXVMXt"
      },
      "source": [
        "## Exporting data\n",
        "\n",
        "The same group of import/export functions can also be used to export data once you've finished doing analysis. These include\n",
        "\n",
        "* `.to_csv()`\n",
        "* `.to_excel()`\n",
        "* `.to_json()`\n",
        "* `.to_html()`\n",
        "* `.to_xml()`\n",
        "\n",
        "To use these, you need to put the name of a data frame *before* the period, and the name you want to give to the exported file as a **string** inside the parentheses. Like this:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anscombe.to_csv(\"anscombe.csv\")\n",
        "anscombe.to_excel(\"anscombe.xlsx\")\n",
        "anscombe.to_json(\"anscombe.json\")\n",
        "anscombe.to_html(\"anscombe.html\")"
      ],
      "metadata": {
        "id": "wpKGvvnDOGWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you run any of those commands you should see the resulting exported file in the Files view on the left in Colab. You can then download that file by hovering over it, clicking the three dots to the right, and selecting *Download*."
      ],
      "metadata": {
        "id": "hfOFvM3gOKPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to Google Drive to import data\n",
        "\n",
        "You can connect your Colab notebook to Google Drive, in order to import files from there.\n",
        "\n",
        "This might seem convenient, but there are two reasons not to do it:\n",
        "\n",
        "Firstly, it is technically more fiddly than the approaches detailed above - especially if your data is in a Google Sheet (rather than a CSV or XLSX file stored in Drive).\n",
        "\n",
        "Secondly, and more importantly, it makes your notebook difficult or impossible for others to replicate (they don't have access to your Drive) - which is one of the key advantages of notebooks.\n",
        "\n",
        "If your data is in Google Drive, then, I would recommend doing one of the following:\n",
        "\n",
        "* [Publish the spreadsheet as a CSV](https://afosto.com/docs/tutorial-publish-csv-online-from-google-sheets/) by going to *File > Share > Publish to the Web* and selecting *CSV* from the dropdown options. The data can now be imported from that URL using the steps detailed above.\n",
        "* Or download the spreadsheet from Drive, and upload it to your notebook\n",
        "\n",
        "If you do want to connect to Google Drive, however, here is some code that shows how to do that (adapted from [this guide](https://koshurai.medium.com/a-comprehensive-guide-to-connecting-google-drive-to-google-colab-e4cc9dcb239c)).\n",
        "\n",
        "When you run the code below you will be asked to agree to allow the notebook to connect to your Google Drive account."
      ],
      "metadata": {
        "id": "XXQAvYv-4MW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the library needed\n",
        "from google.colab import drive\n",
        "#use the mount() function to connect to your Google Drive\n",
        "#and create a folder in the notebook Files\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kupBLzc5-T8",
        "outputId": "8789a37b-9abe-47ed-ba3a-193301f17d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing the data\n",
        "\n",
        "Once that code has run, a new folder called `drive` should now exist inside the *Files* area on the left of the Colab notebook. Inside that will be a subfolder called `MyDrive` with *all* your Google Drive content.\n",
        "\n",
        "You now have a new problem: how to connect to data within your Google Drive file structure.\n",
        "\n",
        "To connect to any spreadsheet you'll first need to find it. That means going to the *Files* area on the left and navigating to the file that you want to import.\n",
        "\n",
        "This can take a while: there is a time lag whenever you expand a folder, as it connects to your drive, and you may need to do a lot of scrolling if you have a lot of files that aren't organised.\n",
        "\n",
        "Once you've found the file that you need, you will need to copy the **path** to that file.\n",
        "\n",
        "To do that, hover over the file and click the three dots that appear. Then select **Copy path**.\n",
        "\n",
        "With that path copied, paste it into a code block, making sure it is inside single or double quotation marks. It will start with `drive/MyDrive/`, e.g.\n",
        "\n",
        "`\"drive/MyDrive/yr2_analysis.csv\"`"
      ],
      "metadata": {
        "id": "_jDzTEGO6k29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#an example of a path to a CSV file stored in Google Drive\n",
        "gdrivepath = 'drive/MyDrive/yr2_analysis.csv'"
      ],
      "metadata": {
        "id": "vTX6Wsg89W76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#an example of a path to an XLSX file stored in Google Drive\n",
        "gdrivepath = '/content/drive/MyDrive/22.xlsx'"
      ],
      "metadata": {
        "id": "4G9FiMTu9Hcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your file is a CSV or XLSX file, then it will end in that file extension (this will be the case if you have uploaded a file into Drive and not converted it to a Google Sheet).\n",
        "\n",
        "However, if it is a Google Sheet, it will end in `.gsheet`, and you have another challenge."
      ],
      "metadata": {
        "id": "5HOa3xkC-6d2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSV files in Google Drive\n",
        "\n",
        "If the file you are trying to fetch from Google Drive ends in .csv then you can import it with `read_csv()` as detailed in the section on importing CSV files earlier in this notebook.\n",
        "\n",
        "That function needs one ingredient: the path to the CSV file.\n",
        "\n",
        "Because we've stored the path to the file in a variable called `gdrivepath`, we just use that as the ingredient in the code below:"
      ],
      "metadata": {
        "id": "w0NFYj9E-IYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import a CSV file from the MyDrive folder\n",
        "df = pd.read_csv(gdrivepath)\n",
        "#show it\n",
        "df"
      ],
      "metadata": {
        "id": "Gx8JIBG77tar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XLSX files in Google Drive\n",
        "\n",
        "If the file you are trying to fetch from Google Drive ends in .xlsx then you can import it using `read_excel()` as detailed in the section on importing XLSX files earlier in this notebook.\n",
        "\n",
        "That function needs *at least* one ingredient - the path to the XLSX file - but by default it will import the first sheet in that XLSX file, so there's a good chance you will need a second ingredient: *which* sheet you want to import from that Excel file. That is identified with the parameter `sheet_name =`.\n",
        "\n",
        "Because we've stored the path to the file in a variable called `gdrivepath`, we just use that as the first ingredient in the code below:\n",
        "\n",
        "For the second ingredient, we've specified we want the 'zero' sheet - this means the first sheet, because Python counts from zero. So if you wanted the second sheet, that would sheet number 1, and the third sheet would be sheet number 2 and so on."
      ],
      "metadata": {
        "id": "Z8vP5qww_bod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import an Excel file from the MyDrive folder, sheet 1 (position 0)\n",
        "df = pd.read_excel(gdrivepath,\n",
        "                   sheet_name = 0)\n",
        "#show it\n",
        "df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MlDzx_EA91Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Sheets in Google Drive\n",
        "\n",
        "Now the tricky bit (and you're probably already regretting taking this route, but let's follow it to the end): importing Google Sheets.\n",
        "\n",
        "To do this we need a special library: `gspread`. The documentation for that library is at https://docs.gspread.org/en/v6.1.4/\n",
        "\n",
        "A [notebook on working with Google Sheets is available here](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=sOm9PFrT8mGG) (go to the section on Google Sheets. This requires authorising with Google Drive *again*, but in a different way. The code below is adapted from that:"
      ],
      "metadata": {
        "id": "Z3RwjWVMAzLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "jiAnhgTS8L9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below will open the first sheet in a spreadsheet - give it the name of your Google Sheet, without any file extensions and without any path. Change `.sheet1` to another sheet number to import a different sheet."
      ],
      "metadata": {
        "id": "GAD_TOf7DN3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import sheet 1 from the named Google Sheet\n",
        "worksheet = gc.open('NAME OF YOUR SHEET').sheet1\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "#create a dataframe from those rows\n",
        "df = pd.DataFrame.from_records(rows)\n",
        "#show the dataframe\n",
        "df"
      ],
      "metadata": {
        "id": "vE0xjQFxBTBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Disconnect from Google Drive\n",
        "\n",
        "To disconnect from Google Drive, run the code below."
      ],
      "metadata": {
        "id": "evU5X3mxAt-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#disconnect from Google Drive\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "f8anjoub7G0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsOTsPaqfJJd"
      },
      "source": [
        "## Importing from GitHub\n",
        "\n",
        "We can import some data from GitHub using the 'Raw' link on [the data file page](https://github.com/paulbradshaw/cleaning/blob/master/dirtydata/Disposals%20by%20region%202012-13%20Table.xls) - but we get an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "3qITLiVcdWI3",
        "outputId": "efd2af0a-feb0-408e-a2e9-47c4c5534946"
      },
      "source": [
        "githublink = \"https://github.com/paulbradshaw/cleaning/blob/master/dirtydata/Disposals%20by%20region%202012-13%20Table.xls?raw=true\"\n",
        "disposals = pd.ExcelFile(githublink)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "XLRDError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0e829e9997d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/paulbradshaw/cleaning/blob/master/dirtydata/Disposals%20by%20region%202012-13%20Table.xls\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;31m# N.B. xlrd.Book has a read attribute too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mformatting_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mon_demand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mragged_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/book.py\u001b[0m in \u001b[0;36mopen_workbook_xls\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_time_stage_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mbiff_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXL_WORKBOOK_GLOBALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbiff_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't determine file's BIFF version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/book.py\u001b[0m in \u001b[0;36mgetbof\u001b[0;34m(self, rqd_stream)\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; met end of file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopcode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbofcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; found %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMY_EOF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/book.py\u001b[0m in \u001b[0;36mbof_error\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reqd: 0x%04x\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrqd_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported format, or corrupt file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m         \u001b[0msavpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0mopcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'\\n\\n\\n\\n\\n\\n<!'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzcvUSYGfYV1"
      },
      "source": [
        "Some googling finds a [solution](https://stackoverflow.com/questions/66648775/how-to-get-link-of-xlsx-file-in-github-to-be-opened-as-a-pandas-dataframe) involving a couple other libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDOTmGiLy0ZR"
      },
      "source": [
        "url = \"https://github.com/paulbradshaw/cleaning/blob/master/dirtydata/Disposals%20by%20region%202012-13%20Table.xls?raw=true\"\n",
        "\n",
        "import requests as rq\n",
        "from io import BytesIO\n",
        "\n",
        "data = rq.get(url).content\n",
        "disposals = pd.ExcelFile(BytesIO(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_ILhcgddvFU",
        "outputId": "9dba9b0e-b503-423e-faa2-6935745d2b58"
      },
      "source": [
        "#https://stackoverflow.com/questions/66648775/how-to-get-link-of-xlsx-file-in-github-to-be-opened-as-a-pandas-dataframe\n",
        "import requests as rq\n",
        "from io import BytesIO\n",
        "\n",
        "url = \"https://github.com/paulbradshaw/cleaning/blob/master/dirtydata/Disposals%20by%20region%202012-13%20Table.xls?raw=true\"\n",
        "data = rq.get(url).content\n",
        "disposals = pd.ExcelFile(BytesIO(data))\n",
        "\n",
        "#what are the sheet names?\n",
        "print(disposals.sheet_names)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['National', 'East Midlands', 'Eastern', 'London', 'North East', 'North West', 'South East', 'South West', 'Wales', 'West Midlands', 'Yorkshire']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFGQTT5efsYO"
      },
      "source": [
        "## Looping through Excel sheets to import them and combine\n",
        "\n",
        "This particular spreadsheet has a different sheet for each area. Here's how we might combine them all into one dataframe:\n",
        "\n",
        "First, we use `read_excel()` with that variable containing the Excel spreadsheet, and specify the first sheet (index 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "BeaSfqv2mhAv",
        "outputId": "e43d17d6-e852-4ca5-fe80-165ff708b82b"
      },
      "source": [
        "#import the first sheet\n",
        "dis1 = pd.read_excel(disposals, sheet_name=0, skiprows=1)\n",
        "dis1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>These figures do not match the data published in Chapter 5 as they are taken from a different data source.</th>\n",
              "      <th>10 - 14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17+</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "      <th>Not Known</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>White</th>\n",
              "      <th>Mixed</th>\n",
              "      <th>Asian or Asian British</th>\n",
              "      <th>Black or Black British</th>\n",
              "      <th>Chinese or Other Ethnic Group</th>\n",
              "      <th>Not Known.1</th>\n",
              "      <th>TOTAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>National</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pre-court</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Reprimand</td>\n",
              "      <td>4726.0</td>\n",
              "      <td>2795.0</td>\n",
              "      <td>2814.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3524.0</td>\n",
              "      <td>9530.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11302.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>458.0</td>\n",
              "      <td>498.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>511.0</td>\n",
              "      <td>13055.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Final Warning</td>\n",
              "      <td>3467.0</td>\n",
              "      <td>2404.0</td>\n",
              "      <td>2491.0</td>\n",
              "      <td>2587.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2350.0</td>\n",
              "      <td>8596.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9562.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>10949.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  These figures do not match the data published in Chapter 5 as they are taken from a different data source.  ...    TOTAL\n",
              "0                                           National                                                          ...      NaN\n",
              "1                                                NaN                                                          ...      NaN\n",
              "2                                         Pre-court                                                           ...      NaN\n",
              "3                                          Reprimand                                                          ...  13055.0\n",
              "4                                      Final Warning                                                          ...  10949.0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqXGjZM48A17"
      },
      "source": [
        "We can rename the columns before we continue, to fix that annoying long first column name.\n",
        "\n",
        "To do this we first have to convert the column names 'series' into a list, using the `list()` function.\n",
        "\n",
        "We then change the first item in that list to what we want it to be.\n",
        "\n",
        "Finally, we replace the existing column 'series' with that newly corrected list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ON-elGE1puF"
      },
      "source": [
        "#create a new list variable from the column names\n",
        "cols = list(dis1.columns)\n",
        "#replace the first item in that list with 'area'\n",
        "cols[0] = \"area\"\n",
        "#replace the column names with the correct list\n",
        "dis1.columns = cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "i0xZSE8G3sav",
        "outputId": "5ac1e6db-5984-4fbd-9206-451a39f6b35d"
      },
      "source": [
        "#check the results\n",
        "dis1.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area</th>\n",
              "      <th>10 - 14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17+</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "      <th>Not Known</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>White</th>\n",
              "      <th>Mixed</th>\n",
              "      <th>Asian or Asian British</th>\n",
              "      <th>Black or Black British</th>\n",
              "      <th>Chinese or Other Ethnic Group</th>\n",
              "      <th>Not Known.1</th>\n",
              "      <th>TOTAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>National</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pre-court</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         area  10 - 14  15  ...  Chinese or Other Ethnic Group  Not Known.1  TOTAL\n",
              "0    National      NaN NaN  ...                            NaN          NaN    NaN\n",
              "1         NaN      NaN NaN  ...                            NaN          NaN    NaN\n",
              "2  Pre-court       NaN NaN  ...                            NaN          NaN    NaN\n",
              "\n",
              "[3 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1CmQp9BoUSI"
      },
      "source": [
        "Now we've fixed that annoyance we can go back to creating our mega-dataframe from all the sheets.\n",
        "\n",
        "To do that we need to loop through the list of sheet names and use each name to grab each sheet with that name - appending it to the dataframe containing the data from sheet 1.\n",
        "\n",
        "We start by creating a copy of our sheet 1 dataframe called 'disposalsall' - this is going to be used to *append* all the other sheets to this base.\n",
        "\n",
        "It will be helpful to *also* store the name of the sheet that the data came from, in a new extra column.\n",
        "\n",
        "The 'i' in the loop below is just a variable name that's used to store each item in the list as we loop through it.\n",
        "\n",
        "That variable 'i' is used in a couple of different ways: to access the sheet of the same name in the Excel workbook; and to fill a column called 'sheet' in our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzlNURkrmZMj",
        "outputId": "954e897f-b814-4807-9a3d-a1ec2c365fa0"
      },
      "source": [
        "#create a dataframe that's a copy of sheet index 0\n",
        "disposalsall = dis1\n",
        "#add a column for the sheet it came from\n",
        "disposalsall['sheet'] = \"National\"\n",
        "\n",
        "#loop through the sheet names from index 1 onwards\n",
        "for i in disposals.sheet_names[1:]:\n",
        "  print(i)\n",
        "  #grab the sheet at that position\n",
        "  currentsheet = pd.read_excel(disposals, sheet_name=i, skiprows=1)\n",
        "  #add a column for the sheet it came from\n",
        "  currentsheet['sheet'] = i\n",
        "  #add to the ongoing dataframe\n",
        "  disposalsall = disposalsall.append(currentsheet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "East Midlands\n",
            "Eastern\n",
            "London\n",
            "North East\n",
            "North West\n",
            "South East\n",
            "South West\n",
            "Wales\n",
            "West Midlands\n",
            "Yorkshire\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIjuTDEfnxLZ",
        "outputId": "3df769a7-fb8d-45c9-d6e6-4632edccdeb9"
      },
      "source": [
        "#show how many rows and cols the one-sheet dataframe has\n",
        "print(dis1.shape)\n",
        "#and the combined dataframe\n",
        "print(disposalsall.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(352, 18)\n",
            "(5792, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MyYoLkRoc9X"
      },
      "source": [
        "An alternative approach would be to measure the *length* of the sheet list and use that to generate indices for `sheet_name=` instead of the actual sheet name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC8jdZ98o81m",
        "outputId": "07df406a-faa5-4ae6-c79c-1376a91e66f2"
      },
      "source": [
        "disposalsall.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "area                              object\n",
              "10 - 14                          float64\n",
              "15                               float64\n",
              "16                               float64\n",
              "17+                              float64\n",
              "Unnamed: 5                       float64\n",
              "Female                           float64\n",
              "Male                             float64\n",
              "Not Known                        float64\n",
              "Unnamed: 9                       float64\n",
              "White                            float64\n",
              "Mixed                            float64\n",
              "Asian or Asian British           float64\n",
              "Black or Black British           float64\n",
              "Chinese or Other Ethnic Group    float64\n",
              "Not Known.1                      float64\n",
              "TOTAL                            float64\n",
              "sheet                             object\n",
              "Unnamed: 0                        object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hewoYoML7fG2"
      },
      "source": [
        "#export the results\n",
        "disposalsall.to_csv(\"alldisposals.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5geK_86TzyL"
      },
      "source": [
        "## More functions for importing data\n",
        "\n",
        "More functions for importing data are detailed on pandas's [documentation on import/export](https://pandas.pydata.org/docs/reference/io.html)\n",
        "\n",
        "[This post also details a range of other ways to import data](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92)"
      ]
    }
  ]
}